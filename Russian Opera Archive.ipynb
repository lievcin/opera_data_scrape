{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOLSHOI\n",
    "#Performance ids are unknown to us, so we'll iterate over 2000 possible ids, if the url works it means this is a valid\n",
    "#entry and we can try to parse it.\n",
    "#Look for relevant performance dates, as this value will reference a hidden table that contains the cast for that day\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "name = \"Russia/Bolshoi.csv\"\n",
    "csv = open(name, \"w\") \n",
    "columnTitleRow = \"opera_title\\t opera_description\\t date\\t role\\t artist\\t url\\n\"\n",
    "csv.write(columnTitleRow)\n",
    "\n",
    "for perf in list(range(1, 2)): #up to 2000\n",
    "    url = \"https://www.bolshoi.ru/en/performances/\" + str(perf) + \"/roles/#all\"\n",
    "    r  = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "    try: \n",
    "        opera_title = soup.select('.navigation_title')[0].text\n",
    "    except IndexError:\n",
    "        opera_title = ''\n",
    "    try:     \n",
    "        opera_description = soup.select(\".perf_desc_title\")[0].text\n",
    "    except IndexError:\n",
    "        opera_description = ''\n",
    "        \n",
    "    for perf_date in soup.select(\".performance_main_content__dates_all .cast_selector\"):\n",
    "        date = perf_date.get('href')[1:]\n",
    "        cast = \".cast_\" + str(date)\n",
    "        for c in soup.select(cast + ' tr'):\n",
    "            role = c.select('.performance_main_content__cast_role_name')[0].text\n",
    "            artist = c.select('.performance_main_content__cast_role_person')[0].text.splitlines()\n",
    "            artist = [ x.strip() for x in artist ]\n",
    "            artist[:] = [value for value in artist if len(value)!=0]\n",
    "            artist = \",\".join(artist)\n",
    "#             print(opera_title + '-' + opera_description + '-' + date + '-' + role + '-' + artist )\n",
    "            row = opera_title + \"\\t\" + opera_description + \"\\t\" + date + \"\\t\" + role + \"\\t\" + artist + \"\\t\" + url + \"\\n\"\n",
    "            csv.write(row)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MARIINSKY\n",
    "#Multiple navigation layers, first season, which by default opens in its first month (usually september - not a url)\n",
    "#then there's a second level month selection, once month is selected a full breakdown opens for each day.\n",
    "#there can be multiple entries on the same day as they have matinees and other theaters.\n",
    "#not all operas have cast\n",
    "#cast table not really a table, just a div with some links, so have to construct pairs out of this.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#We'll need this function as we will have a mix of string and links and garbage\n",
    "def process_marrinsky(row):\n",
    "    if row.name == None:\n",
    "        return row.split('â€“')\n",
    "    else: \n",
    "        return row.text    \n",
    "    \n",
    "def flatten(lst):\n",
    "    for el in lst:\n",
    "        if isinstance(el, list):\n",
    "            yield from el\n",
    "        else:\n",
    "            yield el     \n",
    "            \n",
    "def clean_cast(cast):\n",
    "    cast = [row for row in cast if row.name != 'br']\n",
    "    cast = [process_marrinsky(row) for row in cast]\n",
    "    cast = list(flatten(cast))\n",
    "    cast = [row.strip() for row in cast]\n",
    "    cast = [row for row in cast if len(row) > 0]  \n",
    "    return cast\n",
    "\n",
    "name = \"Russia/Mariinksy.csv\"\n",
    "csv = open(name, \"w\") \n",
    "columnTitleRow = \"opera_title\\t opera_description\\t date\\t role\\t artist\\t url\\n\"\n",
    "csv.write(columnTitleRow)\n",
    "base_url = \"https://www.mariinsky.ru\"\n",
    "\n",
    "for season in list(range(226, 227)): #up to 2000\n",
    "    url = base_url + \"/en/playbill/archive?season=\" + str(season)\n",
    "    r  = requests.get(url)\n",
    "    season_main = BeautifulSoup(r.text, \"html5lib\")\n",
    "    ################################################################################################\n",
    "    #First month of the season is not a URL so we'll parse before we deal with the subsequent pages.\n",
    "    ################################################################################################\n",
    "    for day in season_main.select('div#afisha .row'):\n",
    "        date = day.select(\"time\")[0]['datetime']\n",
    "        opera_title = day.select('.spec_name')[0].text\n",
    "        opera_description = day.select('.descr')[0].text\n",
    "        if 'opera' in opera_description:\n",
    "            opera_url = base_url + day.select('.spec_name a')[0].get('href')\n",
    "            r_opera  = requests.get(opera_url)\n",
    "            opera_main = BeautifulSoup(r_opera.text, \"html5lib\")\n",
    "            if len(opera_main.select('.sostav.inf_block')) > 0:   \n",
    "                cast_table = clean_cast(opera_main.select('.sostav.inf_block')[0].find_all('div')[1:][0].contents)              \n",
    "                artists = []\n",
    "                roles = []\n",
    "                for item in cast_table:\n",
    "                    if cast_table.index(item) % 2 != 0:\n",
    "                        artists.append(item)\n",
    "                    else:\n",
    "                        roles.append(item)\n",
    "\n",
    "                roles_artists = list(zip(roles, artists))    \n",
    "\n",
    "                for cast_row in roles_artists:\n",
    "                    row = opera_title + \"\\t\" + opera_description + \"\\t\" + date + \"\\t\" + cast_row[0] + \"\\t\" + cast_row[1] + \"\\t\" + opera_url + \"\\n\"\n",
    "                    csv.write(row)\n",
    "            else:\n",
    "                row = opera_title + \"\\t\" + opera_description + \"\\t\" + date + \"\\t\" + 'No info' + \"\\t\" + 'No info' + \"\\t\" + opera_url + \"\\n\"\n",
    "                csv.write(row)       \n",
    "    ################################################################################################\n",
    "    for month in season_main.select(\".playbill_archive_months a\"):\n",
    "        month_name = month.text\n",
    "        month_url = base_url + month.get('href')\n",
    "        r_month  = requests.get(month_url)\n",
    "        month_main = BeautifulSoup(r_month.text, \"html5lib\")\n",
    "        for day in month_main.select('div#afisha .row'):\n",
    "            date = day.select(\"time\")[0]['datetime']\n",
    "            opera_title = day.select('.spec_name')[0].text\n",
    "            opera_description = day.select('.descr')[0].text\n",
    "            if 'opera' in opera_description: #Other ballets and concerts have a different structure and are of no interest.            \n",
    "                opera_url = base_url + day.select('.spec_name a')[0].get('href')\n",
    "                r_opera  = requests.get(opera_url)\n",
    "                opera_main = BeautifulSoup(r_opera.text, \"html5lib\")\n",
    "                if len(opera_main.select('.sostav.inf_block')) > 0:   \n",
    "                    cast_table = clean_cast(opera_main.select('.sostav.inf_block')[0].find_all('div')[1:][0].contents)              \n",
    "                    artists = []\n",
    "                    roles = []\n",
    "                    for item in cast_table:\n",
    "                        if cast_table.index(item) % 2 != 0:\n",
    "                            artists.append(item)\n",
    "                        else:\n",
    "                            roles.append(item)\n",
    "\n",
    "                    roles_artists = list(zip(roles, artists))    \n",
    "\n",
    "                    for cast_row in roles_artists:\n",
    "                        row = opera_title + \"\\t\" + opera_description + \"\\t\" + date + \"\\t\" + cast_row[0] + \"\\t\" + cast_row[1] + \"\\t\" + opera_url + \"\\n\"\n",
    "                        csv.write(row)\n",
    "                else:\n",
    "                    row = opera_title + \"\\t\" + opera_description + \"\\t\" + date + \"\\t\" + 'No info' + \"\\t\" + 'No info' + \"\\t\" + opera_url + \"\\n\"\n",
    "                    csv.write(row)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Ekaterinburg Opera\n",
    "#Performances since 2009, no cast data\n",
    "#TODO for some reason writing to csv ends in June 2017... look into this.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "name = \"Russia/Ekaterinburg.csv\"\n",
    "csv = open(name, \"w\") \n",
    "columnTitleRow = \"opera_title\\t opera_description\\t date\\t role\\t artist\\t url\\n\"\n",
    "csv.write(columnTitleRow)\n",
    "\n",
    "years = list(range(2009,2019))\n",
    "months = list(range(1,13))\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        url = 'http://www.uralopera.ru/en/playbill.php/?param=month&year=' + str(year) + '&month=' + str(month)\n",
    "        r  = requests.get(url)\n",
    "        opera_month = BeautifulSoup(r.text, \"html5lib\")\n",
    "        opera_rows = opera_month.select('p tr')\n",
    "        for opera_row in opera_rows:\n",
    "            opera_row_items = opera_row.find_all('td', {'align': 'center'})\n",
    "            if len(opera_row_items) == 3:                 \n",
    "                if 'opera' in opera_row_items[1].text.lower():\n",
    "                    date = opera_row_items[0].text[0:-11]\n",
    "                    opera_title = opera_row_items[1].select('.big_black')[0].text\n",
    "                    row = opera_title + \"\\t\" + 'No info' + \"\\t\" + date + \"\\t\" + 'No info' + \"\\t\" + 'No info' + \"\\t\" + url + \"\\n\"\n",
    "                    csv.write(row)   \n",
    "#                     print(row)\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
